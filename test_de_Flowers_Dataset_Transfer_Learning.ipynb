{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ5DI373a8K7"
      },
      "source": [
        "### **Transfer Learning**\n",
        "Using MobileNet_V2\n",
        "\n",
        "Dataset URL: http://download.tensorflow.org/example_images/flower_photos.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBRGSQQvb35f"
      },
      "source": [
        "## **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLMjZ_J9k7JY"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvMdo8CXlT5F"
      },
      "source": [
        "## **Download Zip File of Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--W1dXphlTij"
      },
      "source": [
        "URL = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "zip_file = tf.keras.utils.get_file(\n",
        "    origin=URL,\n",
        "    fname=\"flower_photos.tgz\",\n",
        "    extract=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjZczlJqlS7N"
      },
      "source": [
        "zip_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrux78NlloAv"
      },
      "source": [
        "!ls /root/.keras/datasets/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPBEQUORlqN3"
      },
      "source": [
        "base_dir = os.path.join(os.path.dirname(zip_file), \"flower_photos\")\n",
        "base_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMsN8jcIl1yz"
      },
      "source": [
        "## **List category names present in dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESWTl1HTl1O6"
      },
      "source": [
        "class_names = [dir for dir in os.listdir(base_dir) if os.path.isdir(base_dir+\"/\"+dir)]\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7yN7RJYlxRR"
      },
      "source": [
        "filenames = list(glob.glob(base_dir+\"/*/*.jpg\"))\n",
        "filenames[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1M6T-TBmSwt"
      },
      "source": [
        "print(\"Total no.of images present in Dataset: {}\".format(len(filenames)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXRueHN5mZKo"
      },
      "source": [
        "categories = []\n",
        "for filename in filenames:\n",
        "  category = filename.split(\"/\")[-2]\n",
        "  categories.append(category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu1TYVXgmjyl"
      },
      "source": [
        "## **Making a Dataframe with filenames and Their categories**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y57otTPxmi_a"
      },
      "source": [
        "dataframe = pd.DataFrame({\n",
        "    \"filename\": filenames,\n",
        "    \"category\": categories\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k33WOc_8mu-1"
      },
      "source": [
        "dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB1Rbh1VmwpM"
      },
      "source": [
        "dataframe['category'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUb8mlW6m3Ui"
      },
      "source": [
        "## **Plotting a random image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td7JpX2Fm2DQ"
      },
      "source": [
        "random_image = np.random.choice(filenames)\n",
        "random_image = tf.keras.preprocessing.image.load_img(random_image)\n",
        "random_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX10v0_SnDBc"
      },
      "source": [
        "random_image = tf.keras.preprocessing.image.img_to_array(random_image)\n",
        "random_image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLVzCojZnObH"
      },
      "source": [
        "Note: All images are in various shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzfKnJnrnSxj"
      },
      "source": [
        "## **Train, test, val Splits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-sjQFaXnK3y"
      },
      "source": [
        "train_full_df, test_df = train_test_split(dataframe, test_size=0.1, random_state=40)\n",
        "train_df, val_df = train_test_split(train_full_df, test_size=0.1, random_state=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu4lxK4unmaX"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhGsGTHVnpx2"
      },
      "source": [
        "train_length = train_df.shape[0]\n",
        "test_length = test_df.shape[0]\n",
        "val_length = val_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLg6t_Umn0Al"
      },
      "source": [
        "## **Data Augmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S84ydj75oXud"
      },
      "source": [
        "Note: If you are using preprocess_input then no need to rescale the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTs_aKmvnyyf"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range = 20,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip = True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    preprocessing_function = preprocess_input\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqnu7C3xoRxS"
      },
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    base_dir+\"/*/\",\n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    batch_size = 32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN-6UZyWo4bQ"
      },
      "source": [
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function = preprocess_input\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rzuGYiRo7zs"
      },
      "source": [
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    base_dir+\"/*/\",\n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    batch_size = 32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbhsjvfRpCfx"
      },
      "source": [
        "## **Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "220Fe1wmpBRz"
      },
      "source": [
        "mobilenet = MobileNetV2(input_shape=[224, 224, 3], weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM75q8hLpOvt"
      },
      "source": [
        "for layer in mobilenet.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwASOpMNpT83"
      },
      "source": [
        "x = tf.keras.layers.GlobalAveragePooling2D()(mobilenet.output)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "x = tf.keras.layers.Dense(len(class_names), activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvSd1FtcpzLT"
      },
      "source": [
        "model = tf.keras.models.Model(inputs=mobilenet.input, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdUvpaxVp6Tw"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwLnnMNXp7fp"
      },
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), #from_logits=false beacause in last predcition layer we specified activation='softmax'\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OToHAfi9qSra"
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    steps_per_epoch = train_length//32,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_length//32,\n",
        "    callbacks = tf.keras.callbacks.EarlyStopping(patience=3)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc_oYeYrq8kS"
      },
      "source": [
        "## **Plot Model Performace**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5ACfZiBqoAD"
      },
      "source": [
        "pd.DataFrame(history.history).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpQn-8strh3i"
      },
      "source": [
        "test_generator = val_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    base_dir+\"/*/\",\n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    batch_size = 32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ESXu8NIruTe"
      },
      "source": [
        "model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8BU-P1QMyav"
      },
      "source": [
        "**Hello Guys! Welcome again**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdriUyPlM6a4"
      },
      "source": [
        "In previous video we saw how to build a model using transfer learning.\n",
        "Now we will look into how to predict a single image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7lPiykN18DF"
      },
      "source": [
        "## **Visualization of Predicted Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtSCnJnwN6j7"
      },
      "source": [
        "1. First we need to know what are the indices assigned to labels by our Generators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcF_5ksQOdsw"
      },
      "source": [
        "class_indices = train_generator.class_indices\n",
        "class_indices #A dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqqzVv_AO7Vw"
      },
      "source": [
        "#Exact all keys from above dictionary\n",
        "class_indices = list(class_indices.keys())\n",
        "class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifghJIJgPC51"
      },
      "source": [
        "test_df.head() #Our test dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksEsFlM8PGhF"
      },
      "source": [
        "#Extract a random value from test_df\n",
        "test_df.iloc[1, :].values #Gives row 1 values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH2mGfYHPQCg"
      },
      "source": [
        "#Generate Random values\n",
        "test_df.iloc[np.random.randint(0, test_length-1), :].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFLYCnCLPe-4"
      },
      "source": [
        "data = test_df.iloc[np.random.randint(0, test_length-1), :].values\n",
        "image_path = data[0]\n",
        "actual_label = data[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONQfTcjNPqK6"
      },
      "source": [
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "image_array = tf.keras.preprocessing.image.img_to_array(image)/255\n",
        "plt.imshow(image_array)\n",
        "plt.title(actual_label)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWbQso6QP_49"
      },
      "source": [
        "#Gather all code at one place\n",
        "data = test_df.iloc[np.random.randint(0, test_length-1), :].values\n",
        "image_path = data[0]\n",
        "actual_label = data[1]\n",
        "\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "image_array = tf.keras.preprocessing.image.img_to_array(image)/255\n",
        "plt.imshow(image_array)\n",
        "plt.title(actual_label)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmC7GyjyQMbN"
      },
      "source": [
        "Now It is generating random image at each iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMeE0jlGQRYu"
      },
      "source": [
        "**Points to Remember:**\n",
        "1. When we are using single images, image should be resized into which model is actually trained. Here our model is trained on image size (224, 224)\n",
        "2. We trained our model in batches. So we need to make this single image into single batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvMkZGMLQJ7d"
      },
      "source": [
        "data = test_df.iloc[np.random.randint(0, test_length-1), :].values\n",
        "image_path = data[0]\n",
        "actual_label = data[1]\n",
        "\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "image_array = tf.keras.preprocessing.image.img_to_array(image)/255\n",
        "image_batch = np.expand_dims(image_array, axis=0) #Batching our single image\n",
        "model.predict(image_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEjSvZoDQ886"
      },
      "source": [
        "Model will produce 5 different probabilities for each image.Beacuse we have 5 classess. The max probability index is our predicted class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV6c_WIAQ6cv"
      },
      "source": [
        "data = test_df.iloc[np.random.randint(0, test_length-1), :].values\n",
        "image_path = data[0]\n",
        "actual_label = data[1]\n",
        "\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "image_array = tf.keras.preprocessing.image.img_to_array(image)/255\n",
        "image_batch = np.expand_dims(image_array, axis=0) #Batching our single image\n",
        "print(\"Predicted label: \",np.argmax(model.predict(image_batch)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zfwjLmMRO6d"
      },
      "source": [
        "data = test_df.iloc[np.random.randint(0, test_length-1), :].values\n",
        "image_path = data[0]\n",
        "actual_label = data[1]\n",
        "\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "image_array = tf.keras.preprocessing.image.img_to_array(image)/255\n",
        "image_batch = np.expand_dims(image_array, axis=0) #Batching our single image\n",
        "predicted_label = class_indices[np.argmax(model.predict(image_batch))]\n",
        "\n",
        "print(\"Predicted label: {}, Actual Label: {}\".format(predicted_label, actual_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOANMB_tRoJ0"
      },
      "source": [
        "Yeah Pretty Good But now we plot Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrw2SZP1RlUg"
      },
      "source": [
        "data = test_df.iloc[np.random.randint(0, test_length-1), :].values\n",
        "image_path = data[0]\n",
        "actual_label = data[1]\n",
        "\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "image_array = tf.keras.preprocessing.image.img_to_array(image)/255\n",
        "image_batch = np.expand_dims(image_array, axis=0) #Batching our single image\n",
        "predicted_label = class_indices[np.argmax(model.predict(image_batch))]\n",
        "plt.imshow(image_array)\n",
        "if actual_label == predicted_label:\n",
        "  plt.title(predicted_label, color='green')\n",
        "else:\n",
        "  plt.title(predicted_label, color='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvHqa7g5SFBa"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for i in range(25):\n",
        "  ax = plt.subplot(5,5,i+1)\n",
        "  data = test_df.iloc[np.random.randint(0, test_length-1), :].values\n",
        "  image_path = data[0]\n",
        "  actual_label = data[1]\n",
        "\n",
        "  image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "  image_array = tf.keras.preprocessing.image.img_to_array(image)/255\n",
        "  image_batch = np.expand_dims(image_array, axis=0) #Batching our single image\n",
        "  predicted_label = class_indices[np.argmax(model.predict(image_batch))]\n",
        "  plt.imshow(image_array)\n",
        "  if actual_label == predicted_label:\n",
        "    plt.title(predicted_label, color='green')\n",
        "  else:\n",
        "    plt.title(predicted_label, color='red')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRxMGemASxOt"
      },
      "source": [
        "**WELCOME**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3XvyhOV39_u"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}